\section{Recursion}

The fundemental components of recursion are
\begin{enumerate}
    \item A base case (or base cases)
    \item A method to split the problem into smaller, similar problems.
\end{enumerate}

\subsection{Master Theorem}

The Master Theorem provides a method for solving recurrence relations
of the form:
\[
    T(n) = aT\left(\frac{n}{b}\right) + f(n)
\]
where:
\begin{itemize}
    \item \( a \geq 1 \) is the number of subproblems in the recursion,
    \item \( b > 1 \) is the factor by which the problem
          size is reduced in each recursive call,
    \item \( f(n) \) is the cost of the work done outside
          the recursive calls, including the cost of dividing the problem and merging results.
\end{itemize}

The theorem provides asymptotic bounds on \( T(n) \)
based on the relationship between \( f(n) \) and \( n^{\log_b a} \).

The asymptotic behavior of \( T(n) \) is determined
by comparing \( f(n) \) with \( n^{\log_b a} \):

\textbf{Case 1: Polynomially Smaller Work at Each Level}

If \( f(n) = O(n^c) \) for some constant \( c < \log_b a \), then:

\[
    T(n) = \Theta(n^{\log_b a})
\]

\textbf{Explanation:} The total cost is dominated by the recursive term, meaning the majority of the work is done at the top levels of recursion.

\textbf{Case 2: Balanced Work at All Levels}

If \( f(n) = \Theta(n^{\log_b a}) \), then:

\[
    T(n) = \Theta(n^{\log_b a} \log n)
\]

\textbf{Explanation:} The work done at each level is roughly the same, so the logarithmic factor arises from the accumulation of work over all levels.

\textbf{Case 3: Work Dominated by the Non-Recursive Term}

If \( f(n) = \Omega(n^c) \) for some constant \( c > \log_b a \), and if the regularity condition holds:

\[
    a f\left(\frac{n}{b}\right) \leq c_1 f(n) \quad \text{for some } c_1 < 1 \text{ and sufficiently large } n,
\]

then:

\[
    T(n) = \Theta(f(n))
\]

\textbf{Explanation:} The majority of the work is done at the base
level of recursion rather than at the top, meaning \( f(n) \)
dominates the total complexity.

\textbf{Example 1: Merge Sort}

The recurrence relation for Merge Sort is:

\[
    T(n) = 2T\left(\frac{n}{2}\right) + O(n)
\]

Here, \( a = 2 \), \( b = 2 \), and \( f(n) = O(n) \). We compare \( f(n) \) with \( n^{\log_2 2} = n \). Since \( f(n) = \Theta(n^{\log_2 2}) \), Case 2 applies:

\[
    T(n) = \Theta(n \log n)
\]

\textbf{Example 2: Binary Search}

The recurrence relation for Binary Search is:

\[
    T(n) = T\left(\frac{n}{2}\right) + O(1)
\]

Here, \( a = 1 \), \( b = 2 \), and \( f(n) = O(1) \). We compare \( f(n) \) with \( n^{\log_2 1} = n^0 = 1 \). Since \( f(n) = O(n^c) \) with \( c = 0 < \log_2 1 = 0 \), Case 1 applies:

\[
    T(n) = \Theta(\log n)
\]

\subsection{Recursion Limit}

Recursive solutions can reach the max recursive depth and
terminate your program early. The way to avoid this is with
an iterative solution. Taking the example of the Fibonacci
sequence, you could implement it as in listing \ref{lst:fib}

\begin{lstlisting}[language=C, label={lst:fib}, caption=Singly Linked List Node Structure]
    #include <stdio.h>

    // Function to calculate the nth Fibonacci number using recursion
    int nthFibonacci(int n){
        // Base case: if n is 0 or 1, return n
        if (n <= 1){
            return n;
        }
        // Recursive case: sum of the two preceding numbers
        return nthFibonacci(n - 1) + nthFibonacci(n - 2);
    }

    int main(){
        int n = 5;
        int result = nthFibonacci(n);
        printf("%d\n", result);
        return 0;
    }
\end{lstlisting}

However, the runtime increases exponentially.
\marginnote{In fact, the runtime increases as $\Phi^n$, where
    $\Phi$ is the golden ratio.}
There is a much better solution, an iterative one.
For listing \ref{lst:fibit} the time complexity is $O(n)$
instead of $O(2^n)$.

\begin{lstlisting}[language=C, label={lst:fibit}, caption=Singly Linked List Node Structure]
    #include <math.h>
    #include <stdio.h>

    // Approximate value of golden ratio
    double PHI = 1.6180339;

    // Fibonacci numbers upto n = 5
    int f[6] = { 0, 1, 1, 2, 3, 5 };

    int fib(int n)
    {
        // Fibonacci numbers for n < 6
        if (n < 6)
            return f[n];

        // Else start counting from
        // 5th term
        int t = 5, fn = 5;

        while (t < n) {
            fn = round(fn * PHI);
            t++;
        }

        return fn;
    }

    int main()
    {
        int n = 9;
        printf("%d th Fibonacci Number = %d\n", n, fib(n));
        return 0;
    }
\end{lstlisting}

\subsection{Space Complexity}

The space complexity of a recursive function is proportional to
the depth of the computation tree, since that gives us the longest
possible path (read: the highest number of frames on the call stack).
For instance, if each frame has a space complexity of $n$, and the
computation tree has a depth of $\log_2(n)$, the space complexity
of the algorithm is $O(n\log(n))$.

\subsection{Tail Recursion}
Tail recursion is a special case of recursion where the recursive
call is the last operation performed in a function before returning
the result. Tail recursion can be transformed into iteration, and in
some languages this is done automatically under the hood.

\begin{lstlisting}[language=C, caption={Regular Recursion}]
    #include <stdio.h>

    int factorial(int n) {
        if (n == 0)
            return 1;
        return n * factorial(n - 1);  
        // Multiplication happens after recursive call
    }

    int main() {
        printf("%d\n", factorial(5)); // Output: 120
        return 0;
    }
\end{lstlisting}

\begin{lstlisting}[language=C, caption={Tail Recursion}, label={lst:tailrecursion}]
    #include <stdio.h>

    int factorial_helper(int n, int acc) {
        if (n == 0)
            return acc;
        return factorial_helper(n - 1, n * acc);  
        // Recursive call is the last operation
    }

    int factorial(int n) {
        return factorial_helper(n, 1);  
        // Start with accumulator = 1
    }

    int main() {
        printf("%d\n", factorial(5)); // Output: 120
        return 0;
    }
\end{lstlisting}

Listing \ref{lst:tailrecursion} is optimized by the C compiler to
perform the algorithm in listing \ref{lst:tailloop}.

\begin{lstlisting}[language=C, caption={Iterative Solution}, label={lst:tailloop}]
    #include <stdio.h>

    int factorial(int n) {
        int acc = 1;  // Initialize the accumulator
        while (n > 0) {
            acc *= n;  // Multiply the accumulator by current n
            n--;       // Decrease n
        }
        return acc;
    }

    int main() {
        printf("%d\n", factorial(5)); // Output: 120
        return 0;
    }

\end{lstlisting}